{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series GIF from GEO Example\n",
    "\n",
    "This example shows how the Capella API can be used to fetch a time series stack of data, read data for a given bounding box directly from cloud optimized geotiffs stored in Capella's S3 bucket, and create a time series gif for visualization. To run this notebook, you will need a Capella API account, with credentials saved in a credentials.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import rasterio\n",
    "import cv2\n",
    "import imageio as io # requires Python 3.5+ see http://imageio.github.io/ for more info\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from pyproj import Transformer\n",
    "from rasterio.windows import Window\n",
    "from skimage import exposure\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up project variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data, BBOX, and time definition\n",
    "bbox = [4.3554, 51.9015, 4.3662, 51.9089]\n",
    "timerange = \"2019-08-01T00:00:00Z/2019-08-30T23:59:00Z\"\n",
    "collections = [\"rotterdam-aerial-mosaic\"]\n",
    "\n",
    "# Windows sizes for filtering\n",
    "FILTSIZE = 3 # window size for speckle filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to apply speckle filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lee_filter(img, size):\n",
    "    img_mean = uniform_filter(img, (size, size))\n",
    "    img_sqr_mean = uniform_filter(img**2, (size, size))\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Apply Linear Stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This performs a linear stretch clipping the lower and upper percent specified\n",
    "def stretch(bands, lower_percent=1, higher_percent=98): # adjust lower and upper percent values for best visualization\n",
    "    import numpy as np\n",
    "    np.ma.array(bands, mask=np.isnan(bands))\n",
    "    out = np.zeros_like(bands)\n",
    "    a = 0 \n",
    "    b = 255 \n",
    "    c = np.percentile(bands, lower_percent)\n",
    "    d = np.percentile(bands, higher_percent)        \n",
    "    t = a + (bands - c) * (b - a) / (d - c)    \n",
    "    t[t<a] = a\n",
    "    t[t>b] = b\n",
    "    out = t\n",
    "    return out.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to reproject bounding box coordinates to the SAR data coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_bbox(bb, epsg):\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", epsg, always_xy=True)\n",
    "    obb = [0] * 4\n",
    "    obb[0], obb[1] = transformer.transform(bb[0], bb[1])\n",
    "    obb[2], obb[3] = transformer.transform(bb[2], bb[3])\n",
    "    return obb   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load API credentials and get an API token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load username and password\n",
    "with open('credentials.json') as f:\n",
    "    data = json.load(f)\n",
    "    username = data['username']\n",
    "    password = data['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get token\n",
    "r = requests.post('https://api.capellaspace.com/token', \n",
    "                  headers = {'Content-Type': 'application/x-www-form-urlencoded'}, auth=(username,password))\n",
    "accesstoken = r.json()[\"accessToken\"]\n",
    "headers = {'Authorization':'Bearer ' + accesstoken}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the API to search for Capella SAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post search filters\n",
    "filters = {\n",
    "    \"datetime\": timerange,\n",
    "    \"bbox\": bbox,\n",
    "    \"collections\": collections,\n",
    "    \"query\": {\"sar:instrument_mode\": {\"eq\": \"stripmap\"},  \n",
    "            \"sar:product_type\": {\"eq\":\"GEO\"}},\n",
    "    \"sort\": [{\"field\": \"dtr:start_datetime\",\"direction\": \"asc\"}],\n",
    "    \"limit\": 50\n",
    "}\n",
    "\n",
    "headers = {'Content-Type': 'application/json',\n",
    "  'Accept': 'application/geo+json', 'Authorization':'Bearer ' + accesstoken}\n",
    "r = requests.post('https://api.capellaspace.com/catalog/search', json=filters, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Order\n",
    "features = r.json()[\"features\"]\n",
    "granulelist = []\n",
    "\n",
    "# Loop over all the features from the response and add to an array for an order\n",
    "for f in features:\n",
    "    item = {\"CollectionId\": f[\"collection\"], \"GranuleId\": f[\"id\"]}\n",
    "    granulelist.append(item)\n",
    "    \n",
    "myorder = {\"Items\": granulelist}\n",
    "#print(myorder)\n",
    "# Post the order and inspect the result\n",
    "r = requests.post('https://api.capellaspace.com/orders', json=myorder, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myorderid = r.json()[\"orderId\"]\n",
    "r = requests.get('https://api.capellaspace.com/orders/' + myorderid + '/download', headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a time series GIF from the time series\n",
    "\n",
    "Ingests the stack of images ordered from the API and assembles a time series GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the results in time\n",
    "features = r.json()\n",
    "assetlist = {}\n",
    "for f in features:\n",
    "    assetlist.update( {f[\"properties\"][\"datetime\"] : f[\"assets\"][\"HH\"][\"href\"]})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = []\n",
    "# Open the file with Rasterio\n",
    "Session = rasterio.Env(\n",
    "            GDAL_DISABLE_READDIR_ON_OPEN='YES',\n",
    "            CPL_VSIL_CURL_USE_HEAD='NO',\n",
    "            )\n",
    "\n",
    "for key in sorted(assetlist.keys()):   \n",
    "    with Session:\n",
    "        filepath = assetlist[key]\n",
    "        timestamp = key\n",
    "        with rasterio.open(filepath) as src:\n",
    "            meta = src.meta\n",
    "            rbbox = reproject_bbox(bbox, src.crs)\n",
    "            w = rasterio.windows.from_bounds(rbbox[0], rbbox[1], rbbox[2], rbbox[3], src.transform)\n",
    "            img1 = src.read(1, window=w)\n",
    "            img1[img1 == meta['nodata']] = 0\n",
    "            img1 = lee_filter(img1, FILTSIZE)\n",
    "            img1 = exposure.adjust_log(img1, gain=10)\n",
    "            \n",
    "            img1_scaled = stretch(img1) \n",
    "\n",
    "            img1_rgb = np.zeros((img1_scaled.shape[0],img1_scaled.shape[1],3), np.uint8)\n",
    "            img1_rgb[:,:,0] = img1_scaled\n",
    "            img1_rgb[:,:,1] = img1_scaled\n",
    "            img1_rgb[:,:,2] = img1_scaled\n",
    "            \n",
    "            img1_rgb = cv2.putText(img1_rgb, text=timestamp, org=(10,30),fontFace=2, fontScale=1, color=(0,255,255), thickness=2)\n",
    "            \n",
    "            timeseries.append(img1_rgb)\n",
    "\n",
    "io.mimsave('timeseries.gif', timeseries, fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<img src=\"timeseries.gif\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
