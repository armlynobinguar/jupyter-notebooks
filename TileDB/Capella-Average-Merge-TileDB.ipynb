{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import json\n",
    "\n",
    "from capella import lee_filter\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.plot import show\n",
    "from rasterio.warp import transform_bounds\n",
    "from rasterio import windows\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.plot import reshape_as_image\n",
    "from skimage import exposure\n",
    "from skimage.restoration import estimate_sigma\n",
    "from scipy.ndimage import morphology\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "\n",
    "# Allow division by zero\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filter.json') as f:\n",
    "    filters = json.load(f)\n",
    "    BBOX = filters['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ! rio capella --credentials credentials.json --area filter.json --collection capella-aerial --limit 50 query\n",
    "fc = json.loads(result[0])\n",
    "features = fc['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def make_inputs(features):\n",
    "    datasets = []\n",
    "    for ft in features:\n",
    "        fid = f\"tiledb://capellaspace/{ft['id']}\"\n",
    "        datasets.append(rasterio.open(fid))\n",
    "\n",
    "    yield datasets\n",
    "    \n",
    "    for ds in datasets:\n",
    "        ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses an additional band as a counter\n",
    "def myaverage(old_data, new_data, old_nodata, new_nodata, index, roff, coff):\n",
    "    mask = ~new_nodata[0]\n",
    "    old_data[0, mask] += new_data[0][mask]\n",
    "    old_data[1, mask] += 1\n",
    "\n",
    "with make_inputs(features) as datasets:\n",
    "    result, _ = merge(datasets, transform_bounds(CRS.from_epsg(4326), datasets[0].crs, *BBOX),\n",
    "                      nodata=0, output_count=2, dtype=np.uint64, method=myaverage)\n",
    "\n",
    "av = result[0] / result[1]\n",
    "equ = exposure.adjust_log(av, gain=10)\n",
    "\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(equ, cmap='gray')\n",
    "ax.set_title(\"Counter method - Mean Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacks inputs and then computes mean across the bands\n",
    "# this is an alternative and flexible way to compute the same result as above\n",
    "def stack_average(old_data, new_data, old_nodata, new_nodata, index, roff, coff):\n",
    "    mask = ~new_nodata[0]\n",
    "    old_data[index, mask] = new_data[0][mask]\n",
    "    \n",
    "with make_inputs(features) as datasets:\n",
    "    output_count = len(datasets) \n",
    "    result, _ = merge(datasets, transform_bounds(CRS.from_epsg(4326), datasets[0].crs, *BBOX),\n",
    "                      nodata=0, output_count=output_count, method=stack_average)\n",
    "\n",
    "av = result.sum(axis=0) / (result != 0).sum(axis=0)        \n",
    "equ = exposure.adjust_log(av, gain=10)\n",
    "\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(equ, cmap='gray')\n",
    "ax.set_title(\"Stack method - Mean Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR weighted average\n",
    "with make_inputs(features) as datasets:\n",
    "    output_count = len(datasets) \n",
    "    stack, _ = merge(datasets, transform_bounds(CRS.from_epsg(4326), datasets[0].crs, *BBOX),\n",
    "                      nodata=0, output_count=output_count, method=stack_average)\n",
    "\n",
    "# estimate the average noise standard deviation across layers in the stack, could use a local window and calculate variance instead of this built-in function\n",
    "img = reshape_as_image(stack)\n",
    "sigmas = np.array(estimate_sigma(img, multichannel=True))\n",
    "\n",
    "# Pixel SNR is the ratio of the local mean to the noise standard deviation for that image in the stack \n",
    "weights = img / sigmas\n",
    "\n",
    "result = (img * weights).sum(axis=2) / weights.sum()\n",
    "equ = exposure.adjust_log(av, gain=10)\n",
    "\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(equ, cmap='gray')\n",
    "ax.set_title(\"Weighted Image\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
